{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9KZQxY4G-3K"
      },
      "source": [
        "# üö¢ Port-to-Rail Logistics: GPU-Accelerated EDA\n",
        "## DGX Spark Frontier Hackathon - December 2025\n",
        "\n",
        "This notebook uses **RAPIDS cuDF** for GPU-accelerated data processing.\n",
        "\n",
        "**Expected Speedups:**\n",
        "- Data loading: ~10-20x faster\n",
        "- GroupBy operations: ~20-50x faster\n",
        "- Rolling windows: ~30x faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phPfPNjwG-3K",
        "outputId": "0807120c-0026-4449-9bc4-1c83e55f5a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 13 09:48:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   35C    P0             56W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMF21k2XG-3L",
        "outputId": "666edfca-5dbb-47dc-8a2b-26ee3a5d8d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ RAPIDS cuDF version: 25.10.00\n",
            "‚úÖ CuPy version: 13.6.0\n",
            "\n",
            "üìÅ Data directory: data\n",
            "üìÅ Output directory: output\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# GPU imports\n",
        "try:\n",
        "    import cudf\n",
        "    import cupy as cp\n",
        "    GPU_AVAILABLE = True\n",
        "    print(f\"‚úÖ RAPIDS cuDF version: {cudf.__version__}\")\n",
        "    print(f\"‚úÖ CuPy version: {cp.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è RAPIDS not available, falling back to pandas\")\n",
        "    import pandas as cudf  # Fallback\n",
        "    import numpy as cp\n",
        "    GPU_AVAILABLE = False\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = Path(\"data\")\n",
        "OUTPUT_DIR = Path(\"output\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"\\nüìÅ Data directory: {DATA_DIR}\")\n",
        "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdkpqUp3G-3L"
      },
      "source": [
        "---\n",
        "## 1. Load Port Activity Data (GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nwv99sXG-3L",
        "outputId": "f69178be-eee4-42aa-8574-aa9027fb9482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded 5,010,140 records in 0.31s\n",
            "Columns: ['date', 'year', 'month', 'day', 'portid', 'portname', 'country', 'ISO3', 'portcalls_container', 'portcalls_dry_bulk', 'portcalls_general_cargo', 'portcalls_roro', 'portcalls_tanker', 'portcalls_cargo', 'portcalls', 'import_container', 'import_dry_bulk', 'import_general_cargo', 'import_roro', 'import_tanker', 'import_cargo', 'import', 'export_container', 'export_dry_bulk', 'export_general_cargo', 'export_roro', 'export_tanker', 'export_cargo', 'export', 'ObjectId']\n"
          ]
        }
      ],
      "source": [
        "t0 = time.time()\n",
        "\n",
        "port_file = \"Daily_Port_Activity_Data_and_Trade_Estimates.csv\"\n",
        "\n",
        "df_all = cudf.read_csv(port_file)\n",
        "\n",
        "load_time = time.time() - t0\n",
        "print(f\"\\nLoaded {len(df_all):,} records in {load_time:.2f}s\")\n",
        "print(f\"Columns: {list(df_all.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dazfKppG-3L",
        "outputId": "3cecbfd7-a707-4ea8-9ade-4f5885b38af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Types:\n",
            "date                        object\n",
            "year                         int64\n",
            "month                        int64\n",
            "day                          int64\n",
            "portid                      object\n",
            "portname                    object\n",
            "country                     object\n",
            "ISO3                        object\n",
            "portcalls_container          int64\n",
            "portcalls_dry_bulk           int64\n",
            "portcalls_general_cargo      int64\n",
            "portcalls_roro               int64\n",
            "portcalls_tanker             int64\n",
            "portcalls_cargo              int64\n",
            "portcalls                    int64\n",
            "import_container           float64\n",
            "import_dry_bulk            float64\n",
            "import_general_cargo       float64\n",
            "import_roro                float64\n",
            "import_tanker              float64\n",
            "import_cargo               float64\n",
            "import                     float64\n",
            "export_container           float64\n",
            "export_dry_bulk            float64\n",
            "export_general_cargo       float64\n",
            "export_roro                float64\n",
            "export_tanker              float64\n",
            "export_cargo               float64\n",
            "export                     float64\n",
            "ObjectId                     int64\n",
            "dtype: object\n",
            "\n",
            "Memory Usage: 1301.0 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"Data Types:\")\n",
        "print(df_all.dtypes)\n",
        "print(f\"\\nMemory Usage: {df_all.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2COLAdumG-3L",
        "outputId": "f2b202e7-e557-4450-d382-c61d0d374181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering to United States...\n",
            "US records: 287,736 (5.7% of total)\n",
            "Filter time: 0.017s\n",
            "US ports: 114\n"
          ]
        }
      ],
      "source": [
        "print(\"Filtering to United States...\")\n",
        "t0 = time.time()\n",
        "\n",
        "df_us = df_all[df_all['country'] == 'United States'].copy()\n",
        "\n",
        "print(f\"US records: {len(df_us):,} ({len(df_us)/len(df_all)*100:.1f}% of total)\")\n",
        "print(f\"Filter time: {time.time()-t0:.3f}s\")\n",
        "print(f\"US ports: {df_us['portname'].nunique()}\")\n",
        "\n",
        "del df_all\n",
        "if GPU_AVAILABLE:\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    cp.get_default_memory_pool().free_all_blocks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Kq-NVRzLG-3L"
      },
      "outputs": [],
      "source": [
        "df_us['date'] = cudf.to_datetime(df_us['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJlVoJT7G-3L"
      },
      "source": [
        "---\n",
        "## 2. Top US Ports Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ozz1jUXG-3L",
        "outputId": "f76ca61a-ba0f-4843-943e-87600e85b30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing port rankings...\n",
            "Aggregation time: 0.011s\n",
            "\n",
            " TOP 20 US PORTS:\n",
            "              portname  portcalls  portcalls_container  container_ratio  total_volume\n",
            "               Houston      50645                 6797        13.420871  3.857563e+08\n",
            "           New Orleans      35207                 2957         8.398898  4.932603e+08\n",
            "   New York-New Jersey      26714                15114        56.577076  5.079804e+08\n",
            "Los Angeles-Long Beach      26176                12990        49.625611  1.089067e+09\n",
            "       South Louisiana      16826                   29         0.172352  3.475274e+08\n",
            "       Port Everglades      15927                10115        63.508508  3.728503e+07\n",
            "              Savannah      15717                11062        70.382388  3.655677e+08\n",
            "             Baltimore      12352                 3442        27.865933  1.726050e+08\n",
            "            Charleston      12100                 8364        69.123967  1.847994e+08\n",
            "        Corpus Christi      11842                   26         0.219558  5.213211e+07\n",
            "          Jacksonville       9071                 4063        44.791092  4.537019e+07\n",
            "      Port of Virginia       8804                 7797        88.562017  2.250122e+08\n",
            "                 Miami       8407                 5522        65.683359  2.492104e+07\n",
            "              Beaumont       8290                   52         0.627262  1.343472e+07\n",
            "               Norfolk       8020                 4625        57.668329  1.338277e+08\n",
            "                Mobile       7942                 2027        25.522538  1.308351e+08\n",
            "              Freeport       7416                  920        12.405609  8.122904e+06\n",
            "           Port Arthur       7351                   78         1.061080  3.923019e+07\n",
            "               Oakland       7342                 7032        95.777717  1.535609e+08\n",
            "          Philadelphia       7220                 3830        53.047091  4.107628e+07\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing port rankings...\")\n",
        "t0 = time.time()\n",
        "\n",
        "port_stats = df_us.groupby('portname').agg({\n",
        "    'portcalls': 'sum',\n",
        "    'portcalls_container': 'sum',\n",
        "    'portcalls_tanker': 'sum',\n",
        "    'portcalls_dry_bulk': 'sum',\n",
        "    'import_cargo': 'sum',\n",
        "    'export_cargo': 'sum',\n",
        "}).reset_index()\n",
        "\n",
        "# total volume = import + export cargo\n",
        "port_stats['total_volume'] = port_stats['import_cargo'] + port_stats['export_cargo']\n",
        "port_stats['container_ratio'] = (port_stats['portcalls_container'] / port_stats['portcalls'] * 100).fillna(0)\n",
        "\n",
        "port_stats = port_stats.sort_values('portcalls', ascending=False)\n",
        "\n",
        "print(f\"Aggregation time: {time.time()-t0:.3f}s\")\n",
        "print(\"\\n TOP 20 US PORTS:\")\n",
        "\n",
        "port_stats_pd = port_stats.to_pandas() if GPU_AVAILABLE else port_stats\n",
        "display_cols = ['portname', 'portcalls', 'portcalls_container', 'container_ratio', 'total_volume']\n",
        "print(port_stats_pd.head(20)[display_cols].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx70BBOIG-3L",
        "outputId": "c5746bae-e675-4dfd-e7de-aa045fb212e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PORT TYPE DISTRIBUTION:\n",
            "port_type\n",
            "Bulk Terminal    81\n",
            "Mixed            19\n",
            "Container Hub    14\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TOP 10 CONTAINER PORTS:\n",
            "              portname  portcalls_container  container_ratio\n",
            "   New York-New Jersey                15114        56.577076\n",
            "Los Angeles-Long Beach                12990        49.625611\n",
            "              Savannah                11062        70.382388\n",
            "       Port Everglades                10115        63.508508\n",
            "            Charleston                 8364        69.123967\n",
            "      Port of Virginia                 7797        88.562017\n",
            "               Oakland                 7032        95.777717\n",
            "               Houston                 6797        13.420871\n",
            "                 Miami                 5522        65.683359\n",
            "               Norfolk                 4625        57.668329\n"
          ]
        }
      ],
      "source": [
        "port_stats_pd['port_type'] = port_stats_pd['container_ratio'].apply(\n",
        "    lambda x: 'Container Hub' if x > 60 else ('Bulk Terminal' if x < 20 else 'Mixed')\n",
        ")\n",
        "\n",
        "print(\"\\nPORT TYPE DISTRIBUTION:\")\n",
        "print(port_stats_pd['port_type'].value_counts())\n",
        "\n",
        "print(\"\\nTOP 10 CONTAINER PORTS:\")\n",
        "container_ports = port_stats_pd.nlargest(10, 'portcalls_container')[['portname', 'portcalls_container', 'container_ratio']]\n",
        "print(container_ports.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPUze_nOG-3L"
      },
      "source": [
        "---\n",
        "## 3. GPU-Accelerated Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtbm7KiBG-3L",
        "outputId": "ac41289b-fc4a-4486-9a89-6cb098292726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Focusing on top 30 ports...\n",
            "Records: 75,720\n",
            "280004    New Orleans\n",
            "280005    New Orleans\n",
            "280052    New Orleans\n",
            "280056    New Orleans\n",
            "280060    New Orleans\n",
            "Name: portname, dtype: object\n",
            "\n",
            " --------------------------------\n",
            "4134395    Marcus Hook\n",
            "4134396    Marcus Hook\n",
            "4134397    Marcus Hook\n",
            "4134398    Marcus Hook\n",
            "4134399    Marcus Hook\n",
            "Name: portname, dtype: object\n"
          ]
        }
      ],
      "source": [
        "TOP_N = 30\n",
        "top_ports = port_stats_pd.head(TOP_N)['portname'].tolist()\n",
        "\n",
        "print(f\"Focusing on top {TOP_N} ports...\")\n",
        "df = df_us[df_us['portname'].isin(top_ports)].copy()\n",
        "print(f\"Records: {len(df):,}\")\n",
        "\n",
        "print(df.head()['portname'])\n",
        "print(\"\\n --------------------------------\")\n",
        "print(df.tail()['portname'])\n",
        "\n",
        "df = df.sort_values(['portname', 'date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MheW_Y0-G-3L",
        "outputId": "2cb61275-ed10-4b64-9fb2-d1c94855fbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding temporal features...\n",
            "‚è±Ô∏è Temporal features: 0.017s\n"
          ]
        }
      ],
      "source": [
        "# TEMPORAL FEATURES (GPU-accelerated)\n",
        "print(\"Adding temporal features...\")\n",
        "t0 = time.time()\n",
        "\n",
        "df['day_of_week'] = df['date'].dt.dayofweek\n",
        "df['day_of_year'] = df['date'].dt.dayofyear\n",
        "df['week_of_year'] = df['date'].dt.isocalendar().week.astype('int32')\n",
        "df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
        "df['is_month_end'] = df['date'].dt.is_month_end.astype('int8')\n",
        "\n",
        "if GPU_AVAILABLE:\n",
        "    df['month_sin'] = cp.sin(2 * cp.pi * df['month'].values / 12)\n",
        "    df['month_cos'] = cp.cos(2 * cp.pi * df['month'].values / 12)\n",
        "    df['dow_sin'] = cp.sin(2 * cp.pi * df['day_of_week'].values / 7)\n",
        "    df['dow_cos'] = cp.cos(2 * cp.pi * df['day_of_week'].values / 7)\n",
        "else:\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "\n",
        "print(f\"‚è±Ô∏è Temporal features: {time.time()-t0:.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpExBmgOG-3L",
        "outputId": "8adf6409-c764-4901-f57f-40cb4f39cfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding cargo features...\n",
            "Cargo features: 0.048s\n"
          ]
        }
      ],
      "source": [
        "print(\"Adding cargo features...\")\n",
        "t0 = time.time()\n",
        "\n",
        "# Safe division helper\n",
        "def safe_div(a, b, fill=0):\n",
        "    result = a / b\n",
        "    result = result.fillna(fill)\n",
        "    if GPU_AVAILABLE:\n",
        "        result = result.replace([cp.inf, -cp.inf], fill)\n",
        "    else:\n",
        "        result = result.replace([np.inf, -np.inf], fill)\n",
        "    return result\n",
        "\n",
        "df['container_pct'] = safe_div(df['portcalls_container'], df['portcalls_cargo']) * 100\n",
        "df['tanker_pct'] = safe_div(df['portcalls_tanker'], df['portcalls_cargo']) * 100\n",
        "df['bulk_pct'] = safe_div(df['portcalls_dry_bulk'], df['portcalls_cargo']) * 100\n",
        "\n",
        "df['import_export_ratio'] = safe_div(df['import_cargo'], df['export_cargo'], fill=1)\n",
        "df['trade_balance'] = df['export_cargo'] - df['import_cargo']\n",
        "df['total_volume'] = df['import_cargo'] + df['export_cargo']\n",
        "df['volume_per_call'] = safe_div(df['total_volume'], df['portcalls_cargo'])\n",
        "\n",
        "print(f\"Cargo features: {time.time()-t0:.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cv9u1_GG-3M",
        "outputId": "a7bc334c-5883-414d-a4c7-9a2c785ebb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing rolling statistics...\n",
            "‚è±Ô∏è Rolling stats: 0.072s\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing rolling statistics...\")\n",
        "t0 = time.time()\n",
        "\n",
        "# cuDF doesn't support groupby().transform() with rolling\n",
        "# Instead, compute per-port using a loop or apply pattern\n",
        "\n",
        "if GPU_AVAILABLE:\n",
        "    # Method: Sort by port+date, compute rolling, then handle port boundaries\n",
        "    df = df.sort_values(['portname', 'date']).reset_index(drop=True)\n",
        "\n",
        "    # For each window, compute rolling stats per port\n",
        "    for window in [7, 14, 30]:\n",
        "        # Use groupby + rolling (cuDF 23.10+ syntax)\n",
        "        df[f'ma{window}'] = df.groupby('portname')['portcalls'].rolling(window, min_periods=1).mean().reset_index(drop=True)\n",
        "        df[f'std{window}'] = df.groupby('portname')['portcalls'].rolling(window, min_periods=1).std().reset_index(drop=True).fillna(0)\n",
        "\n",
        "    # Import rolling\n",
        "    df['import_ma7'] = df.groupby('portname')['import_cargo'].rolling(7, min_periods=1).mean().reset_index(drop=True)\n",
        "else:\n",
        "    # Pandas version\n",
        "    for window in [7, 14, 30]:\n",
        "        df[f'ma{window}'] = df.groupby('portname')['portcalls'].transform(\n",
        "            lambda x: x.rolling(window, min_periods=1).mean()\n",
        "        )\n",
        "        df[f'std{window}'] = df.groupby('portnaame')['portcalls'].transform(\n",
        "            lambda x: x.rolling(window, min_periods=1).std()\n",
        "        ).fillna(0)\n",
        "\n",
        "    df['import_ma7'] = df.groupby('portname')['import_cargo'].transform(\n",
        "        lambda x: x.rolling(7, min_periods=1).mean()\n",
        "    )\n",
        "\n",
        "print(f\"‚è±Ô∏è Rolling stats: {time.time()-t0:.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0PMqt-sG-3M",
        "outputId": "8a16afaf-d326-4568-eda7-cbb1da484d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing z-scores and surge detection...\n",
            "‚è±Ô∏è Surge detection: 0.029s\n"
          ]
        }
      ],
      "source": [
        "# Z-SCORES & SURGE DETECTION\n",
        "print(\"Computing z-scores and surge detection...\")\n",
        "t0 = time.time()\n",
        "\n",
        "# Z-scores\n",
        "df['zscore_7d'] = safe_div(df['portcalls'] - df['ma7'], df['std7'].replace(0, 1))\n",
        "df['zscore_30d'] = safe_div(df['portcalls'] - df['ma30'], df['std30'].replace(0, 1))\n",
        "\n",
        "# Surge flags\n",
        "df['surge_2std'] = (df['zscore_7d'] > 2).astype('int8')\n",
        "df['surge_3std'] = (df['zscore_7d'] > 3).astype('int8')\n",
        "\n",
        "# Volume surge (50% above 7-day avg)\n",
        "df['volume_surge'] = (df['import_cargo'] > df['import_ma7'] * 1.5).astype('int8')\n",
        "\n",
        "print(f\"‚è±Ô∏è Surge detection: {time.time()-t0:.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGYTDkxEG-3M",
        "outputId": "80d1ebb2-b14a-459d-8351-fb4a08e757cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding lag features...\n",
            "‚è±Ô∏è Lag features: 0.077s\n"
          ]
        }
      ],
      "source": [
        "# LAG FEATURES (for prediction)\n",
        "print(\"Adding lag features...\")\n",
        "t0 = time.time()\n",
        "\n",
        "for lag in [1, 3, 7, 14]:\n",
        "    df[f'calls_lag{lag}'] = df.groupby('portname')['portcalls'].shift(lag)\n",
        "    df[f'import_lag{lag}'] = df.groupby('portname')['import_cargo'].shift(lag)\n",
        "\n",
        "# Momentum\n",
        "df['momentum_3d'] = df.groupby('portname')['portcalls'].diff(3)\n",
        "df['momentum_7d'] = df.groupby('portname')['portcalls'].diff(7)\n",
        "df['pct_change'] = df.groupby('portname')['portcalls'].pct_change()\n",
        "\n",
        "print(f\"‚è±Ô∏è Lag features: {time.time()-t0:.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PORT-LEVEL STATIC FEATURES\n",
        "print(\"Adding port-level features...\")\n",
        "t0 = time.time()\n",
        "\n",
        "# Activity rank - compute differently for cuDF\n",
        "if GPU_AVAILABLE:\n",
        "    # Calculate mean portcalls per port\n",
        "    port_avg = df.groupby('portname')['portcalls'].mean().reset_index()\n",
        "    port_avg.columns = ['portname', 'avg_portcalls']\n",
        "    port_avg['activity_rank'] = port_avg['avg_portcalls'].rank(ascending=False)\n",
        "\n",
        "    # Merge back to main df\n",
        "    df = df.merge(port_avg[['portname', 'activity_rank']], on='portname', how='left')\n",
        "\n",
        "    # Port tier - use merge instead of map\n",
        "    def get_tier(rank):\n",
        "        if rank <= 10: return 'mega'\n",
        "        elif rank <= 20: return 'major'\n",
        "        else: return 'medium'\n",
        "\n",
        "    # Create tier mapping as a dataframe\n",
        "    port_avg['port_tier'] = port_avg['activity_rank'].to_pandas().apply(get_tier)\n",
        "    tier_df = port_avg[['portname', 'port_tier']].copy()\n",
        "\n",
        "    # Convert tier_df to cudf if needed\n",
        "    if not isinstance(tier_df, cudf.DataFrame):\n",
        "        tier_df = cudf.DataFrame(tier_df)\n",
        "\n",
        "    df = df.merge(tier_df, on='portname', how='left')\n",
        "else:\n",
        "    # Pandas version\n",
        "    port_rank = df.groupby('portname')['portcalls'].mean().rank(ascending=False)\n",
        "    df['activity_rank'] = df['portname'].map(port_rank)\n",
        "\n",
        "    def get_tier(rank):\n",
        "        if rank <= 10: return 'mega'\n",
        "        elif rank <= 20: return 'major'\n",
        "        else: return 'medium'\n",
        "\n",
        "    tier_map = {port: get_tier(rank) for port, rank in port_rank.items()}\n",
        "    df['port_tier'] = df['portname'].map(tier_map)\n",
        "\n",
        "print(f\"‚è±Ô∏è Port features: {time.time()-t0:.3f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPJLrxc_Iw8I",
        "outputId": "5d0ec8a0-607e-4e08-b011-7e2083e88deb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding port-level features...\n",
            "‚è±Ô∏è Port features: 0.029s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA1YuD0AG-3M",
        "outputId": "079a67ec-0dd3-4f1f-bb9f-8a56f53c92af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating prediction targets...\n",
            "‚è±Ô∏è Targets created: 0.039s\n",
            "\n",
            "üìä Total features: 76\n"
          ]
        }
      ],
      "source": [
        "# PREDICTION TARGETS\n",
        "print(\"Creating prediction targets...\")\n",
        "t0 = time.time()\n",
        "\n",
        "# Next-day forecasts (24h)\n",
        "df['target_calls_1d'] = df.groupby('portname')['portcalls'].shift(-1)\n",
        "df['target_import_1d'] = df.groupby('portname')['import_cargo'].shift(-1)\n",
        "df['target_surge_1d'] = df.groupby('portname')['surge_2std'].shift(-1)\n",
        "\n",
        "# 3-day forecasts (72h)\n",
        "df['target_calls_3d'] = df.groupby('portname')['portcalls'].shift(-3)\n",
        "\n",
        "# 7-day forecasts\n",
        "df['target_calls_7d'] = df.groupby('portname')['portcalls'].shift(-7)\n",
        "\n",
        "print(f\"‚è±Ô∏è Targets created: {time.time()-t0:.3f}s\")\n",
        "print(f\"\\nüìä Total features: {len(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ken9R7tyG-3M"
      },
      "source": [
        "---\n",
        "## 5. üìà Surge Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdWN8E4gG-3M",
        "outputId": "bc4f17ee-1cc0-4491-ef5c-6e5805a0f793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing surge statistics...\n",
            "‚è±Ô∏è Surge analysis: 0.018s\n",
            "\n",
            "üö® TOP 15 SURGE-PRONE PORTS:\n",
            "        portname  surge_2std_days  surge_rate  max_zscore  avg_calls\n",
            "          Duluth               41    1.624406    2.267787   1.708003\n",
            "  Wilmington, DE               29    1.148970    2.267787   2.223851\n",
            "     Port Arthur               26    1.030111    2.267787   2.912441\n",
            "     New Orleans               23    0.911252    2.234217  13.948891\n",
            "Port of Virginia               21    0.832013    2.206837   3.488114\n",
            "    Lake Charles               21    0.832013    2.267787   2.143027\n",
            "          Tacoma               21    0.832013    2.267787   2.378368\n",
            "      Texas City               20    0.792393    2.267787   1.981379\n",
            "           Miami               20    0.792393    2.267787   3.330824\n",
            "          Mobile               20    0.792393    2.225052   3.146593\n",
            "       Galveston               18    0.713154    2.165251   1.684628\n",
            "     Marcus Hook               18    0.713154    2.165251   1.814976\n",
            "    Jacksonville               18    0.713154    2.164007   3.593899\n",
            "           Tampa               17    0.673534    2.214776   2.547147\n",
            "        Beaumont               16    0.633914    2.267787   3.284469\n"
          ]
        }
      ],
      "source": [
        "# SURGE STATISTICS\n",
        "print(\"Computing surge statistics...\")\n",
        "t0 = time.time()\n",
        "\n",
        "if GPU_AVAILABLE:\n",
        "    # cuDF-compatible aggregation\n",
        "    surge_stats = df.groupby('portname').agg({\n",
        "        'surge_2std': 'sum',\n",
        "        'surge_3std': 'sum',\n",
        "        'volume_surge': 'sum',\n",
        "        'portcalls': ['mean', 'std', 'max'],\n",
        "        'zscore_7d': 'max',\n",
        "        'import_cargo': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Flatten column names\n",
        "    surge_stats.columns = ['portname', 'surge_2std_days', 'surge_3std_days', 'volume_surge_days',\n",
        "                           'avg_calls', 'std_calls', 'max_calls', 'max_zscore', 'avg_import']\n",
        "\n",
        "    # Get total days per port using merge instead of map\n",
        "    days_per_port = df.groupby('portname').size().reset_index()\n",
        "    days_per_port.columns = ['portname', 'total_days']\n",
        "\n",
        "    surge_stats = surge_stats.merge(days_per_port, on='portname', how='left')\n",
        "    surge_stats['surge_rate'] = surge_stats['surge_2std_days'] / surge_stats['total_days'] * 100\n",
        "\n",
        "    # Sort by surge count\n",
        "    surge_stats = surge_stats.sort_values('surge_2std_days', ascending=False)\n",
        "\n",
        "    # Convert to pandas for display\n",
        "    surge_stats_pd = surge_stats.to_pandas()\n",
        "else:\n",
        "    surge_stats = df.groupby('portname').agg({\n",
        "        'surge_2std': 'sum',\n",
        "        'surge_3std': 'sum',\n",
        "        'volume_surge': 'sum',\n",
        "        'portcalls': ['mean', 'std', 'max'],\n",
        "        'zscore_7d': 'max',\n",
        "        'import_cargo': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    surge_stats.columns = ['portname', 'surge_2std_days', 'surge_3std_days', 'volume_surge_days',\n",
        "                           'avg_calls', 'std_calls', 'max_calls', 'max_zscore', 'avg_import']\n",
        "\n",
        "    days_per_port = df.groupby('portname').size()\n",
        "    surge_stats['total_days'] = surge_stats['portname'].map(days_per_port)\n",
        "    surge_stats['surge_rate'] = surge_stats['surge_2std_days'] / surge_stats['total_days'] * 100\n",
        "\n",
        "    surge_stats = surge_stats.sort_values('surge_2std_days', ascending=False)\n",
        "    surge_stats_pd = surge_stats\n",
        "\n",
        "print(f\"‚è±Ô∏è Surge analysis: {time.time()-t0:.3f}s\")\n",
        "\n",
        "print(\"\\nüö® TOP 15 SURGE-PRONE PORTS:\")\n",
        "print(surge_stats_pd.head(15)[['portname', 'surge_2std_days', 'surge_rate', 'max_zscore', 'avg_calls']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBsd3m2JG-3M",
        "outputId": "7199ec82-100b-438f-a362-3117f7172edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä SURGE SUMMARY:\n",
            "  Total surge events (2œÉ): 523\n",
            "  Total volume surge events: 16,111\n",
            "  Average surge rate: 0.69%\n"
          ]
        }
      ],
      "source": [
        "# Overall surge statistics\n",
        "total_surge_2std = surge_stats_pd['surge_2std_days'].sum()\n",
        "total_volume_surge = surge_stats_pd['volume_surge_days'].sum()\n",
        "avg_surge_rate = surge_stats_pd['surge_rate'].mean()\n",
        "\n",
        "print(\"\\nüìä SURGE SUMMARY:\")\n",
        "print(f\"  Total surge events (2œÉ): {total_surge_2std:,}\")\n",
        "print(f\"  Total volume surge events: {total_volume_surge:,}\")\n",
        "print(f\"  Average surge rate: {avg_surge_rate:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6K0BX40G-3M"
      },
      "source": [
        "---\n",
        "## 6. üåä Load Additional Data (Chokepoints, Disruptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3zRs-PbG-3M",
        "outputId": "5754334c-119c-469d-8bb5-3c9505e90b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading chokepoint data...\n",
            "‚úÖ Loaded 70,728 chokepoint records in 0.016s\n",
            "üåä Chokepoints: ['Suez Canal', 'Panama Canal', 'Bosporus Strait', 'Bab el-Mandeb Strait', 'Malacca Strait', 'Strait of Hormuz', 'Cape of Good Hope', 'Gibraltar Strait', 'Dover Strait', 'Oresund Strait', 'Taiwan Strait', 'Korea Strait', 'Tsugaru Strait', 'Luzon Strait', 'Lombok Strait', 'Ombai Strait', 'Bohai Strait', 'Torres Strait', 'Sunda Strait', 'Makassar Strait', 'Magellan Strait', 'Yucatan Channel', 'Windward Passage', 'Mona Passage', 'Balabac Strait', 'Bering Strait', 'Mindoro Strait', 'Kerch Strait']\n"
          ]
        }
      ],
      "source": [
        "# Load chokepoint data\n",
        "print(\"Loading chokepoint data...\")\n",
        "t0 = time.time()\n",
        "\n",
        "chokepoint_file = \"Daily_Chokepoints_Data.csv\"\n",
        "df_choke = cudf.read_csv(chokepoint_file)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(df_choke):,} chokepoint records in {time.time()-t0:.3f}s\")\n",
        "print(f\"üåä Chokepoints: {df_choke['portname'].unique().to_pandas().tolist() if GPU_AVAILABLE else df_choke['portname'].unique().tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t74a4Zo9G-3M",
        "outputId": "ac5c6afc-7aa7-47c6-c4f8-aa5ba36062e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üåä CHOKEPOINT ACTIVITY (by avg daily cargo ships):\n",
            "            portname  n_cargo_mean  n_cargo_max  n_container_mean\n",
            "       Taiwan Strait    186.418052          345         85.375297\n",
            "        Korea Strait    162.794141          314         56.684481\n",
            "        Bohai Strait    139.294537          347         21.382423\n",
            "      Malacca Strait    120.007126          198         49.560966\n",
            "        Dover Strait    108.002375          173         34.317894\n",
            "    Gibraltar Strait     87.964766          127         32.038401\n",
            "     Bosporus Strait     72.866587          126          8.236738\n",
            "     Makassar Strait     47.211006           77          1.981394\n",
            "        Luzon Strait     46.079177          160          6.667458\n",
            "   Cape of Good Hope     45.790974          156          9.440222\n",
            "      Mindoro Strait     41.636975           78          1.590657\n",
            "      Oresund Strait     37.042755           85          5.853523\n",
            "    Strait of Hormuz     36.897862           63         14.812747\n",
            "          Suez Canal     36.754157           70         15.170230\n",
            "Bab el-Mandeb Strait     35.452890           75         13.958432\n"
          ]
        }
      ],
      "source": [
        "# Chokepoint statistics\n",
        "choke_stats = df_choke.groupby('portname').agg({\n",
        "    'n_cargo': ['mean', 'std', 'max'],\n",
        "    'n_container': ['mean', 'max'],\n",
        "    'capacity_cargo': ['mean', 'max']\n",
        "}).reset_index()\n",
        "\n",
        "choke_stats.columns = ['_'.join(col).strip('_') for col in choke_stats.columns]\n",
        "choke_stats = choke_stats.sort_values('n_cargo_mean', ascending=False)\n",
        "\n",
        "choke_pd = choke_stats.to_pandas() if GPU_AVAILABLE else choke_stats\n",
        "print(\"\\nüåä CHOKEPOINT ACTIVITY (by avg daily cargo ships):\")\n",
        "print(choke_pd[['portname', 'n_cargo_mean', 'n_cargo_max', 'n_container_mean']].head(15).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3WRbg1YG-3M",
        "outputId": "0a9a1a6e-c98b-4c00-a98b-580bef6c1368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading disruption events...\n",
            "‚úÖ Loaded 125 disruption events\n",
            "\n",
            "‚ö†Ô∏è EVENT TYPES:\n",
            "eventtype\n",
            "TC    70\n",
            "EQ    29\n",
            "FL    14\n",
            "DR     4\n",
            "OT     4\n",
            "VO     2\n",
            "WF     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üö® ALERT LEVELS:\n",
            "alertlevel\n",
            "RED       124\n",
            "ORANGE      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load disruption events\n",
        "print(\"\\nLoading disruption events...\")\n",
        "disrupt_file = \"portwatch_disruptions_database_-3602226124776604501.csv\"\n",
        "df_disrupt = cudf.read_csv(disrupt_file)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(df_disrupt):,} disruption events\")\n",
        "\n",
        "disrupt_pd = df_disrupt.to_pandas() if GPU_AVAILABLE else df_disrupt\n",
        "print(\"\\n‚ö†Ô∏è EVENT TYPES:\")\n",
        "print(disrupt_pd['eventtype'].value_counts())\n",
        "\n",
        "print(\"\\nüö® ALERT LEVELS:\")\n",
        "print(disrupt_pd['alertlevel'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DBCSzeXG-3M"
      },
      "source": [
        "---\n",
        "## 7. üíæ Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVvwkJuTG-3M",
        "outputId": "f7a8452f-3587-4b35-d328-808581f55c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed data...\n",
            "Clean records: 75,690\n",
            "‚úÖ Saved: gpu_port_features.parquet (0.101s)\n",
            "‚úÖ Saved: gpu_surge_analysis.csv\n",
            "‚úÖ Saved: gpu_chokepoints.parquet\n"
          ]
        }
      ],
      "source": [
        "# Clean and save\n",
        "print(\"Saving processed data...\")\n",
        "\n",
        "# Remove rows with NaN targets\n",
        "df_clean = df.dropna(subset=['target_calls_1d'])\n",
        "print(f\"Clean records: {len(df_clean):,}\")\n",
        "\n",
        "# Save as parquet (GPU-accelerated write)\n",
        "t0 = time.time()\n",
        "\n",
        "# Full dataset\n",
        "df_clean.to_parquet(OUTPUT_DIR / \"gpu_port_features.parquet\", index=False)\n",
        "print(f\"‚úÖ Saved: gpu_port_features.parquet ({time.time()-t0:.3f}s)\")\n",
        "\n",
        "# Save surge analysis\n",
        "surge_stats_pd.to_csv(OUTPUT_DIR / \"gpu_surge_analysis.csv\", index=False)\n",
        "print(f\"‚úÖ Saved: gpu_surge_analysis.csv\")\n",
        "\n",
        "# Save chokepoints\n",
        "df_choke.to_parquet(OUTPUT_DIR / \"gpu_chokepoints.parquet\", index=False)\n",
        "print(f\"‚úÖ Saved: gpu_chokepoints.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfYIs5RPG-3M",
        "outputId": "6e914531-ad0e-4177-990b-5bf5625562a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä FEATURE SUMMARY:\n",
            "  Features: 64\n",
            "  Targets: 5\n",
            "  Records: 75,690\n",
            "  Ports: 30\n"
          ]
        }
      ],
      "source": [
        "# Feature summary\n",
        "feature_cols = [c for c in df_clean.columns if not c.startswith('target_')\n",
        "                and c not in ['date', 'portname', 'portid', 'country', 'ISO3', 'ObjectId', 'port_tier']]\n",
        "target_cols = [c for c in df_clean.columns if c.startswith('target_')]\n",
        "\n",
        "feature_info = {\n",
        "    'features': feature_cols,\n",
        "    'targets': target_cols,\n",
        "    'n_features': len(feature_cols),\n",
        "    'n_targets': len(target_cols),\n",
        "    'n_records': len(df_clean),\n",
        "    'n_ports': int(df_clean['portname'].nunique()),\n",
        "    'gpu_processed': GPU_AVAILABLE\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"gpu_feature_info.json\", 'w') as f:\n",
        "    json.dump(feature_info, f, indent=2)\n",
        "\n",
        "print(f\"\\nüìä FEATURE SUMMARY:\")\n",
        "print(f\"  Features: {len(feature_cols)}\")\n",
        "print(f\"  Targets: {len(target_cols)}\")\n",
        "print(f\"  Records: {len(df_clean):,}\")\n",
        "print(f\"  Ports: {df_clean['portname'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D9_tpJPG-3M"
      },
      "source": [
        "---\n",
        "## 8. ü§ñ Quick ML Baseline (GPU with cuML)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scXe4KX1G-3M",
        "outputId": "b1006ea0-2167-440c-ed06-82a326bfce50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ cuML available for GPU-accelerated ML!\n"
          ]
        }
      ],
      "source": [
        "# Try cuML for GPU-accelerated ML\n",
        "try:\n",
        "    from cuml.ensemble import RandomForestRegressor as cuRF\n",
        "    from cuml.model_selection import train_test_split as cu_split\n",
        "    from cuml.metrics import mean_absolute_error as cu_mae, r2_score as cu_r2\n",
        "    CUML_AVAILABLE = True\n",
        "    print(\"‚úÖ cuML available for GPU-accelerated ML!\")\n",
        "except ImportError:\n",
        "    from sklearn.ensemble import RandomForestRegressor as cuRF\n",
        "    from sklearn.model_selection import train_test_split as cu_split\n",
        "    from sklearn.metrics import mean_absolute_error as cu_mae, r2_score as cu_r2\n",
        "    CUML_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è cuML not available, using sklearn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK4sl5QwG-3M",
        "outputId": "53d284fc-6ad7-4727-e533-e0611754482c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing ML data...\n",
            "ML Features: 63\n",
            "Training samples: 50,000\n"
          ]
        }
      ],
      "source": [
        "# Prepare data for ML\n",
        "print(\"Preparing ML data...\")\n",
        "\n",
        "# Get numeric features only\n",
        "numeric_cols = df_clean.select_dtypes(include=['number']).columns.tolist()\n",
        "ml_features = [c for c in numeric_cols if not c.startswith('target_')\n",
        "               and c not in ['ObjectId', 'year']]\n",
        "\n",
        "print(f\"ML Features: {len(ml_features)}\")\n",
        "\n",
        "# Sample for faster training\n",
        "n_samples = min(50000, len(df_clean))\n",
        "if GPU_AVAILABLE:\n",
        "    df_sample = df_clean.sample(n=n_samples, random_state=42)\n",
        "    X = df_sample[ml_features].fillna(0)\n",
        "    y = df_sample['target_calls_1d'].fillna(0)\n",
        "\n",
        "    # Replace inf\n",
        "    X = X.replace([cp.inf, -cp.inf], 0)\n",
        "else:\n",
        "    df_sample = df_clean.sample(n=n_samples, random_state=42)\n",
        "    X = df_sample[ml_features].fillna(0).replace([np.inf, -np.inf], 0)\n",
        "    y = df_sample['target_calls_1d'].fillna(0)\n",
        "\n",
        "print(f\"Training samples: {len(X):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehEd3e8kG-3M",
        "outputId": "d601c10a-dde9-41a1-a829-78bbbe3d0716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 40,000, Test: 10,000\n"
          ]
        }
      ],
      "source": [
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = cu_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train: {len(X_train):,}, Test: {len(X_test):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynyn9vUJG-3M",
        "outputId": "7a0eec1d-7b81-4f14-f2dd-934e39de128d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "‚è±Ô∏è Training time: 0.58s\n"
          ]
        }
      ],
      "source": [
        "# Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "t0 = time.time()\n",
        "\n",
        "if CUML_AVAILABLE:\n",
        "    model = cuRF(n_estimators=100, max_depth=12, random_state=42)\n",
        "else:\n",
        "    model = cuRF(n_estimators=100, max_depth=12, n_jobs=-1, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "train_time = time.time() - t0\n",
        "\n",
        "print(f\"‚è±Ô∏è Training time: {train_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqT-R171G-3M",
        "outputId": "d24a8eb1-166d-4293-f747-39e0dbeafb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n",
            "\n",
            "üéØ MODEL PERFORMANCE:\n",
            "  MAE: 1.49 port calls\n",
            "  R¬≤: 0.785 (78.5% variance explained)\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "print(\"Evaluating model...\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "if CUML_AVAILABLE:\n",
        "    mae = cu_mae(y_test, y_pred)\n",
        "    r2 = cu_r2(y_test, y_pred)\n",
        "else:\n",
        "    mae = cu_mae(y_test, y_pred)\n",
        "    r2 = cu_r2(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nüéØ MODEL PERFORMANCE:\")\n",
        "print(f\"  MAE: {mae:.2f} port calls\")\n",
        "print(f\"  R¬≤: {r2:.3f} ({r2*100:.1f}% variance explained)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "GBGQCZTaG-3N"
      },
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "if hasattr(model, 'feature_importances_'):\n",
        "    importance = model.feature_importances_\n",
        "    if GPU_AVAILABLE and hasattr(importance, 'to_numpy'):\n",
        "        importance = importance.to_numpy()\n",
        "    elif GPU_AVAILABLE and hasattr(importance, 'get'):\n",
        "        importance = importance.get()\n",
        "\n",
        "    feat_imp = pd.DataFrame({\n",
        "        'feature': ml_features,\n",
        "        'importance': importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nüìä TOP 20 IMPORTANT FEATURES:\")\n",
        "    print(feat_imp.head(20).to_string(index=False))\n",
        "\n",
        "    # Save\n",
        "    feat_imp.to_csv(OUTPUT_DIR / \"gpu_feature_importance.csv\", index=False)\n",
        "    print(f\"\\n‚úÖ Saved: gpu_feature_importance.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaYFEq__G-3N"
      },
      "source": [
        "---\n",
        "## 9. üìã Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQygrCkrG-3N",
        "outputId": "495a8234-e626-4903-fc18-e22166027d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üéâ GPU EDA COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "üìä DATA PROCESSED:\n",
            "  ‚Ä¢ Port records: 75,690\n",
            "  ‚Ä¢ US ports analyzed: 30\n",
            "  ‚Ä¢ Chokepoint records: 70,728\n",
            "  ‚Ä¢ Disruption events: 125\n",
            "\n",
            "üîß FEATURES ENGINEERED:\n",
            "  ‚Ä¢ Total features: 64\n",
            "  ‚Ä¢ Prediction targets: 5\n",
            "\n",
            "üö® SURGE ANALYSIS:\n",
            "  ‚Ä¢ Total surge events (2œÉ): 523\n",
            "  ‚Ä¢ Average surge rate: 0.69%\n",
            "\n",
            "ü§ñ BASELINE MODEL:\n",
            "  ‚Ä¢ MAE: 1.49 port calls\n",
            "  ‚Ä¢ R¬≤: 0.785\n",
            "\n",
            "üíæ OUTPUT FILES:\n",
            "  ‚Ä¢ gpu_chokepoints.parquet: 4.0 MB\n",
            "  ‚Ä¢ gpu_feature_info.json: 1.4 KB\n",
            "  ‚Ä¢ gpu_port_features.parquet: 11.4 MB\n",
            "  ‚Ä¢ gpu_surge_analysis.csv: 3.7 KB\n",
            "\n",
            "‚úÖ GPU Accelerated: True\n",
            "‚úÖ cuML Used: True\n"
          ]
        }
      ],
      "source": [
        "# Final summary\n",
        "print(\"=\"*80)\n",
        "print(\"üéâ GPU EDA COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìä DATA PROCESSED:\")\n",
        "print(f\"  ‚Ä¢ Port records: {len(df_clean):,}\")\n",
        "print(f\"  ‚Ä¢ US ports analyzed: {df_clean['portname'].nunique()}\")\n",
        "print(f\"  ‚Ä¢ Chokepoint records: {len(df_choke):,}\")\n",
        "print(f\"  ‚Ä¢ Disruption events: {len(df_disrupt):,}\")\n",
        "\n",
        "print(f\"\\nüîß FEATURES ENGINEERED:\")\n",
        "print(f\"  ‚Ä¢ Total features: {len(feature_cols)}\")\n",
        "print(f\"  ‚Ä¢ Prediction targets: {len(target_cols)}\")\n",
        "\n",
        "print(f\"\\nüö® SURGE ANALYSIS:\")\n",
        "print(f\"  ‚Ä¢ Total surge events (2œÉ): {total_surge_2std:,}\")\n",
        "print(f\"  ‚Ä¢ Average surge rate: {avg_surge_rate:.2f}%\")\n",
        "\n",
        "print(f\"\\nü§ñ BASELINE MODEL:\")\n",
        "print(f\"  ‚Ä¢ MAE: {mae:.2f} port calls\")\n",
        "print(f\"  ‚Ä¢ R¬≤: {r2:.3f}\")\n",
        "\n",
        "print(f\"\\nüíæ OUTPUT FILES:\")\n",
        "for f in sorted(OUTPUT_DIR.glob(\"gpu_*\")):\n",
        "    size = f.stat().st_size / 1024\n",
        "    unit = \"KB\"\n",
        "    if size > 1024:\n",
        "        size /= 1024\n",
        "        unit = \"MB\"\n",
        "    print(f\"  ‚Ä¢ {f.name}: {size:.1f} {unit}\")\n",
        "\n",
        "print(f\"\\n‚úÖ GPU Accelerated: {GPU_AVAILABLE}\")\n",
        "print(f\"‚úÖ cuML Used: {CUML_AVAILABLE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbYe_8CFG-3N"
      },
      "source": [
        "---\n",
        "## üöÄ Next Steps\n",
        "\n",
        "1. **Deep Learning Models**: Use the features to train LSTM/Transformer for time series forecasting\n",
        "2. **Multi-port correlation**: Analyze how surges propagate between ports\n",
        "3. **Chokepoint impact**: Link chokepoint congestion to US port arrivals\n",
        "4. **Rail terminal prediction**: Estimate containers heading to rail based on import_container"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFKgTlqLM6zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}